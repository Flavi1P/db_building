{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f33cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import polars as pl\n",
    "import glob\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from geopy.distance import geodesic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f60126",
   "metadata": {},
   "source": [
    "### Open Gliders files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2f128a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Get list of NetCDF files\n",
    "nc_files = glob.glob(\"C:/Users/flapet/OneDrive - NOC/Documents/IDAPro/lib/db_building/data/glider/nc_profiled/*.nc\")\n",
    "\n",
    "# Read and concatenate datasets\n",
    "for file in nc_files:\n",
    "    ds = xr.open_dataset(file, decode_times=True)\n",
    "    glider_name = ds.attrs.get(\"trajectory\").split(\"_\")[0]\n",
    "    # Select variables of interest\n",
    "    vars_of_interest = [\"TIME\", \"DEPTH\", \"TEMP\", \"CHLA\", \"BBP700\", \"ABS_SALINITY\", \"MOLAR_DOXY\", \"PROFILE_NUMBER\", \"LATITUDE\", \"LONGITUDE\"]\n",
    "    ds_sel = ds[vars_of_interest]\n",
    "    # Convert to pandas DataFrame, then to polars DataFrame\n",
    "    df_pd = ds_sel.to_dataframe().reset_index()\n",
    "    df_pl = pl.from_pandas(df_pd)\n",
    "\n",
    "    #Use only profiling data (-1 is surfacing behavior)\n",
    "    df_pl = df_pl.filter(pl.col(\"PROFILE_NUMBER\") > 0)\n",
    "\n",
    "    df_pl = df_pl.with_columns((pl.col(\"PROFILE_NUMBER\").cast(pl.String) + \"_\" + glider_name).alias(\"profile_id\"))\n",
    "    print(f\"{file} processed, shape: {df_pl.shape}\")\n",
    "\n",
    "    # Concatenate DataFrames\n",
    "    if 'df_concat' in locals():\n",
    "        df_concat = pl.concat([df_concat, df_pl])\n",
    "    else:\n",
    "        df_concat = df_pl\n",
    "\n",
    "# Add a 'glider_name' column by extracting the part before '_' in 'profile_id'\n",
    "df_concat = df_concat.with_columns(\n",
    "    pl.col(\"profile_id\").str.split(\"_\").list.get(1).alias(\"glider_name\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74dca750",
   "metadata": {},
   "source": [
    "### Open CTD files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b724050c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ctd(filepath):\n",
    "\n",
    "\n",
    "    # Read column names from line 27 (R skips 26 lines, so read line 27 as header)\n",
    "    cols = pd.read_csv(filepath, skiprows=26, nrows=0)\n",
    "    cols_name = cols.columns.tolist()\n",
    "\n",
    "    # Read actual data (R skips 28 lines, so data starts at line 29)\n",
    "    dat = pd.read_csv(filepath, skiprows=28, header=None)\n",
    "    dat.columns = cols_name\n",
    "\n",
    "    # Read raw lines for metadata\n",
    "    with open(filepath, \"r\") as f:\n",
    "        raw_dat = f.readlines()\n",
    "\n",
    "    # Extract LON\n",
    "    lon_line = next(line for line in raw_dat if \"LON\" in line)\n",
    "    lon = float(re.search(r\"=(.*)\", lon_line).group(1).strip())\n",
    "\n",
    "    # Extract LAT\n",
    "    lat_line = next(line for line in raw_dat if \"LAT\" in line)\n",
    "    lat = float(re.search(r\"=(.*)\", lat_line).group(1).strip())\n",
    "\n",
    "    # Add to dataframe\n",
    "    dat[\"lon\"] = lon\n",
    "    dat[\"lat\"] = lat\n",
    "\n",
    "    # Extract DATE (second match, as in R)\n",
    "    date_lines = [line for line in raw_dat if \"DATE\" in line]\n",
    "    date_str = re.search(r\"=(.*)\", date_lines[1]).group(1).strip()\n",
    "    date_val = pd.to_datetime(date_str).date()\n",
    "\n",
    "    # Extract TIME\n",
    "    time_line = next(line for line in raw_dat if \"TIME\" in line)\n",
    "    time_str = re.search(r\"= (.*)\", time_line).group(1).strip()\n",
    "\n",
    "    # Parse TIME (e.g. \"1025\" → \"10:25\")\n",
    "    time_str_formatted = re.sub(r\"^([0-9]{2})([0-9]+)$\", r\"\\1:\\2\", time_str)\n",
    "    time_val = pd.to_datetime(time_str_formatted, format=\"%H:%M\").time()\n",
    "\n",
    "    # Combine date and time\n",
    "    datetime_val = datetime.combine(date_val, time_val)\n",
    "\n",
    "    # Add datetime to dataframe\n",
    "    dat[\"datetime\"] = datetime_val\n",
    "    return dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f00ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parent directory\n",
    "parent_dir = \"C:/Users/flapet/OneDrive - NOC/Documents/IDAPro/lib/db_building/data/CTD/DY180/74EQ20240522_ct1\"\n",
    "\n",
    "# List to hold each parsed DataFrame\n",
    "dataframes = []\n",
    "idx = 1\n",
    "# Loop through all files in the parent directory and subdirectories\n",
    "for root, dirs, files in os.walk(parent_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\"):\n",
    "            file_path = os.path.join(root, file)\n",
    "            try:\n",
    "                df = read_ctd(file_path)\n",
    "                df['profile_idx'] = idx\n",
    "                dataframes.append(df)\n",
    "                idx += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to read {file_path}: {e}\")\n",
    "\n",
    "# Combine all dataframes into one\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Display summary\n",
    "print(f\"Loaded {len(dataframes)} files. Combined shape: {combined_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffef015",
   "metadata": {},
   "source": [
    "### Make a plot to show distance of gliders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170c78fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'profile_id' and 'glider_name', then aggregate median datetime, longitude, latitude\n",
    "summary = (\n",
    "    df_concat\n",
    "    .group_by(['profile_id', 'glider_name'])\n",
    "    .agg([\n",
    "        pl.col('TIME').median().alias('median_datetime'),\n",
    "        pl.col('LONGITUDE').median().alias('median_longitude'),\n",
    "        pl.col('LATITUDE').median().alias('median_latitude')\n",
    "    ])\n",
    "    .sort('median_datetime')\n",
    ")\n",
    "\n",
    "# Convert to pandas DataFrame for easier display if needed\n",
    "summary_pd = summary.to_pandas()\n",
    "summary_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff8685c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary table from combined_df with one line per profile (grouped by 'datetime', 'lon', 'lat')\n",
    "ctd_summary = (\n",
    "    combined_df[['datetime', 'lon', 'lat', 'profile_idx']]\n",
    "    .drop_duplicates()\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "ctd_summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ea2e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare arrays for glider and CTD profile locations and times\n",
    "glider_times = summary_pd['median_datetime'].values\n",
    "glider_lons = summary_pd['median_longitude'].values\n",
    "glider_lats = summary_pd['median_latitude'].values\n",
    "\n",
    "ctd_times = ctd_summary['datetime'].values\n",
    "ctd_lons = ctd_summary['lon'].values\n",
    "ctd_lats = ctd_summary['lat'].values\n",
    "\n",
    "# For each glider profile, find the closest CTD profile in time and compute distance\n",
    "closest_ctd_idx = []\n",
    "closest_time_diff = []\n",
    "distance_km = []\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "for g_time, g_lat, g_lon in zip(glider_times, glider_lats, glider_lons):\n",
    "    # Find index of closest CTD profile in time\n",
    "    time_diffs = abs(ctd_times - g_time)\n",
    "    idx = time_diffs.argmin()\n",
    "    closest_ctd_idx.append(idx)\n",
    "    closest_time_diff.append(time_diffs[idx])\n",
    "    # Compute distance in km, handle nan coordinates\n",
    "    glider_pos = (g_lat, g_lon)\n",
    "    ctd_pos = (ctd_lats[idx], ctd_lons[idx])\n",
    "    if np.isfinite(g_lat) and np.isfinite(g_lon) and np.isfinite(ctd_lats[idx]) and np.isfinite(ctd_lons[idx]):\n",
    "        dist = geodesic(glider_pos, ctd_pos).km\n",
    "    else:\n",
    "        dist = np.nan\n",
    "    distance_km.append(dist)\n",
    "\n",
    "# Add results to summary_pd\n",
    "summary_pd['closest_ctd_idx'] = closest_ctd_idx\n",
    "summary_pd['ctd_time_diff'] = closest_time_diff\n",
    "summary_pd['ctd_distance_km'] = distance_km\n",
    "\n",
    "summary_pd[['profile_id', 'glider_name', 'median_datetime', 'closest_ctd_idx', 'ctd_time_diff', 'ctd_distance_km']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dfb376",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the last CTD profile datetime\n",
    "last_ctd_time = ctd_times[-1]\n",
    "\n",
    "# Filter summary_pd to only include glider profiles up to the last CTD profile datetime\n",
    "mask = summary_pd['median_datetime'] <= last_ctd_time\n",
    "filtered = summary_pd[mask]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "for name, group in filtered.groupby('glider_name'):\n",
    "    plt.plot(group['median_datetime'], group['ctd_distance_km'], label=name, marker='o', linestyle='-')\n",
    "\n",
    "plt.xlabel('Datetime')\n",
    "plt.ylabel('Distance to Closest CTD Profile (km)')\n",
    "plt.ylim(0, 50)\n",
    "plt.title('Glider Distance from CTD Over Time')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16692e67",
   "metadata": {},
   "source": [
    "### Generate a list of possible candidate profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7b8233",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "def find_candidate_glider_ctd_pairs(glider_df, ctd_df, time_thresh_hr=2, dist_thresh_km=5):\n",
    "    \"\"\"\n",
    "    Identify all pairs of glider and CTD profiles within specified time (hours) and distance (km) thresholds.\n",
    "    \n",
    "    Returns a DataFrame of matching pairs with details.\n",
    "    \"\"\"\n",
    "    matches = []\n",
    "    \n",
    "    for _, g_row in glider_df.iterrows():\n",
    "        for _, c_row in ctd_df.iterrows():\n",
    "            # Time difference\n",
    "            time_diff_hr = abs((g_row['median_datetime'] - c_row['datetime']).total_seconds()) / 3600.0\n",
    "            if time_diff_hr > time_thresh_hr:\n",
    "                continue\n",
    "\n",
    "            # Skip if coordinates are missing\n",
    "            if pd.isnull(g_row['median_latitude']) or pd.isnull(g_row['median_longitude']) \\\n",
    "               or pd.isnull(c_row['lat']) or pd.isnull(c_row['lon']):\n",
    "                continue\n",
    "\n",
    "            # Distance in kilometers\n",
    "            dist_km = geodesic(\n",
    "                (g_row['median_latitude'], g_row['median_longitude']),\n",
    "                (c_row['lat'], c_row['lon'])\n",
    "            ).km\n",
    "\n",
    "            if dist_km > dist_thresh_km:\n",
    "                continue\n",
    "\n",
    "            matches.append({\n",
    "                'glider_profile_id': g_row['profile_id'],\n",
    "                'glider_name': g_row['glider_name'],\n",
    "                'ctd_profile_id': c_row.get('profile_idx', None),  # default to None if not present\n",
    "                'time_diff_hr': time_diff_hr,\n",
    "                'dist_km': dist_km\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(matches)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f433cd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the find_candidate_glider_ctd_pairs function with filtered and ctd_summary\n",
    "candidates = find_candidate_glider_ctd_pairs(\n",
    "    filtered,\n",
    "    ctd_summary,\n",
    "    time_thresh_hr=12,\n",
    "    dist_thresh_km=20\n",
    ")\n",
    "\n",
    "print(f\"Found {len(candidates)} candidate glider-CTD profile pairs within 12hr and 20km.\")\n",
    "# Show the first 5 candidates\n",
    "candidates[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61d6ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_heatmap_glider_df(glider_name, df, time_bins, dist_bins):\n",
    "    \"\"\"\n",
    "    Plot cumulative 2D histogram (heatmap) of matchups from a DataFrame for a specific glider.\n",
    "    \n",
    "    Parameters:\n",
    "    - glider_name: str, the glider to filter\n",
    "    - df: pd.DataFrame with required columns: \n",
    "          'glider_profile_id', 'glider_name', 'ctd_profile_id', 'time_diff_hr', 'dist_km'\n",
    "    - time_bins: array-like, bin edges for time (in hours)\n",
    "    - dist_bins: array-like, bin edges for distance (in km)\n",
    "    \"\"\"\n",
    "\n",
    "    # Filter DataFrame for selected glider\n",
    "    df_g = df[df['glider_name'] == glider_name]\n",
    "    if df_g.empty:\n",
    "        print(f\"No matchups found for glider '{glider_name}'.\")\n",
    "        return\n",
    "\n",
    "    # Extract arrays for histogram\n",
    "    time_diffs = df_g['time_diff_hr'].values\n",
    "    dist_kms = df_g['dist_km'].values\n",
    "\n",
    "    # Compute 2D histogram\n",
    "    H, xedges, yedges = np.histogram2d(time_diffs, dist_kms, bins=[time_bins, dist_bins])\n",
    "\n",
    "    # Cumulative sum along both axes\n",
    "    H_cum = H.cumsum(axis=0).cumsum(axis=1)\n",
    "\n",
    "    # Plot heatmap\n",
    "    X, Y = np.meshgrid(yedges, xedges)\n",
    "    plt.figure(figsize=(9, 7))\n",
    "    plt.pcolormesh(X, Y, H_cum, cmap='PuBu', shading='auto')\n",
    "    plt.colorbar(label='Cumulative Number of Matchups')\n",
    "    plt.xlabel('Distance Threshold (km)')\n",
    "    plt.ylabel('Time Threshold (hr)')\n",
    "    plt.title(f'Cumulative Matchups by Time/Distance\\nGlider: {glider_name}')\n",
    "\n",
    "    # Annotate each cell with value\n",
    "    for i in range(H_cum.shape[0]):\n",
    "        for j in range(H_cum.shape[1]):\n",
    "            val = int(H_cum[i, j])\n",
    "            if val > 0:\n",
    "                x_center = (yedges[j] + yedges[j+1]) / 2\n",
    "                y_center = (xedges[i] + xedges[i+1]) / 2\n",
    "                color = 'white' if val > H_cum.max() / 2 else 'black'\n",
    "                plt.text(x_center, y_center, str(val), ha='center', va='center', fontsize=8, color=color)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e41c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_bins = np.arange(0, 13, 2) \n",
    "dist_bins = np.arange(0, 11, 2)\n",
    "# Choose a specific glider, e.g., \"Nelson\"\n",
    "glider_of_interest = \"Nelson\"\n",
    "plot_heatmap_glider_df(glider_of_interest, candidates, time_bins, dist_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca700e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap_glider_df(\"Doombar\", candidates, time_bins, dist_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490b4b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap_glider_df(\"Churchill\", candidates, time_bins, dist_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a871a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap_glider_df(\"Cabot\", candidates, time_bins, dist_bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc062ff",
   "metadata": {},
   "source": [
    "### Look at depth bin match up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf509c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate DEPTH values per profile_id in df_concat (polars DataFrame)\n",
    "# We'll use group_by and apply interpolation using polars' .interpolate() method\n",
    "\n",
    "df_concat = (\n",
    "    df_concat\n",
    "    .sort(['profile_id', 'TIME'])\n",
    "    .with_columns([\n",
    "        pl.col('DEPTH')\n",
    "        .interpolate()\n",
    "        .over('profile_id')\n",
    "        .alias('DEPTH_interp')\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a21195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a 'depth_bin' column to df_concat, binning 'DEPTH' in 50m intervals\n",
    "df_concat = df_concat.with_columns(\n",
    "    (-(pl.col(\"DEPTH_interp\") // 5)).cast(pl.Int32).alias(\"depth_bin\"))\n",
    "# Add a 'depth_bin' column to combined_df, binning 'CTDPRS' in 50m intervals\n",
    "combined_df['depth_bin'] = pd.to_numeric(combined_df['CTDPRS'], errors='coerce') // 5\n",
    "combined_df['depth_bin'] = combined_df['depth_bin'].astype('Int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cfa435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'profile_id', 'glider_name', and 'depth_bin', then aggregate median for selected variables\n",
    "glider_binned = (\n",
    "    df_concat\n",
    "    .group_by(['profile_id', 'glider_name', 'depth_bin'])\n",
    "    .agg([\n",
    "        pl.col('TEMP').median().alias('median_temp'),\n",
    "        pl.col('ABS_SALINITY').median().alias('median_salinity'),\n",
    "        pl.col('CHLA').median().alias('median_chla'),\n",
    "        pl.col('BBP700').median().alias('median_bbp'),\n",
    "        pl.col('MOLAR_DOXY').median().alias('median_doxy')\n",
    "    ])\n",
    "    .sort(['profile_id', 'depth_bin'])\n",
    ")\n",
    "# Remove rows with any missing values in the aggregated table\n",
    "glider_binned = glider_binned.drop_nulls()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b62252",
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "ctd_binned = (\n",
    "    combined_df\n",
    "    .groupby(['datetime', 'lon', 'lat', 'depth_bin', 'profile_idx'], as_index=False)\n",
    "    .agg({\n",
    "        ' CTDTMP': 'median',\n",
    "        ' CTDSAL': 'median',\n",
    "        ' CTDTURB': 'median',\n",
    "        ' CTDOXY': 'median',\n",
    "        ' CTDFLUOR': 'median'\n",
    "    })\n",
    ")\n",
    "\n",
    "ctd_binned = pl.from_pandas(ctd_binned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb4465f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert candidates to polars DataFrame\n",
    "candidates_pl = pl.from_pandas(candidates)\n",
    "\n",
    "# Join all depth bins for each glider_profile_id from glider_binned\n",
    "# This will add all depth-bin data for each candidate glider profile\n",
    "candidates_with_bins = candidates_pl.join(\n",
    "    glider_binned,\n",
    "    left_on=\"glider_profile_id\",\n",
    "    right_on=\"profile_id\",\n",
    "    how=\"inner\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe27bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join ctd_binned data to candidates_with_bins using ctd_profile_id and depth_bin\n",
    "final_matched = candidates_with_bins.join(\n",
    "    ctd_binned,\n",
    "    left_on=[\"ctd_profile_id\", \"depth_bin\"],\n",
    "    right_on=[\"profile_idx\", \"depth_bin\"],\n",
    "    how=\"inner\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe9422e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pybroom\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "def type2_regression_r2_pybroom(x, y):\n",
    "    \"\"\"\n",
    "    Compute R2 for type 2 regression (major axis regression) using pybroom.\n",
    "    \"\"\"\n",
    "    # Remove NaNs\n",
    "    mask = np.isfinite(x) & np.isfinite(y)\n",
    "    x_clean = x[mask]\n",
    "    y_clean = y[mask]\n",
    "    \n",
    "    if len(x_clean) < 2:\n",
    "        return np.nan\n",
    "    \n",
    "    # Type 2 regression slope\n",
    "    s_yx = np.std(y_clean, ddof=1) / np.std(x_clean, ddof=1)\n",
    "    r = np.corrcoef(x_clean, y_clean)[0, 1]\n",
    "    slope = np.sign(r) * s_yx\n",
    "    intercept = np.mean(y_clean) - slope * np.mean(x_clean)\n",
    "    \n",
    "    # Create a simple linear model for pybroom compatibility\n",
    "    # We'll use the type 2 regression parameters we calculated\n",
    "    y_pred = slope * x_clean + intercept\n",
    "    \n",
    "    # Calculate R2\n",
    "    ss_res = np.sum((y_clean - y_pred) ** 2)\n",
    "    ss_tot = np.sum((y_clean - np.mean(y_clean)) ** 2)\n",
    "    r2 = 1 - ss_res / ss_tot if ss_tot > 0 else np.nan\n",
    "    \n",
    "    return r2\n",
    "\n",
    "# Updated analysis using pybroom concepts\n",
    "# Group the final_matched DataFrame by 'glider_profile_id' and 'ctd_profile_id'\n",
    "grouped = final_matched.to_pandas().groupby(['glider_profile_id', 'ctd_profile_id'])\n",
    "\n",
    "# Define var_pairs: pairs of columns to compare between glider and CTD datasets\n",
    "var_pairs = [\n",
    "    ('median_temp', ' CTDTMP', 'r2_temp'),\n",
    "    ('median_salinity', ' CTDSAL', 'r2_salinity'),\n",
    "    ('median_chla', ' CTDFLUOR', 'r2_chla'),\n",
    "    ('median_bbp', ' CTDTURB', 'r2_bbp'),\n",
    "    ('median_doxy', ' CTDOXY', 'r2_doxy')\n",
    "]\n",
    "\n",
    "results = []\n",
    "for keys, group in grouped:\n",
    "    row = {'glider_profile_id': keys[0], 'ctd_profile_id': keys[1]}\n",
    "    # Add time and distance from the first row in group\n",
    "    first_row = group.iloc[0]\n",
    "    row['time_diff_hr'] = first_row['time_diff_hr']\n",
    "    row['dist_km'] = first_row['dist_km']\n",
    "    \n",
    "    for g_col, c_col, out_col in var_pairs:\n",
    "        x = group[g_col].to_numpy()\n",
    "        y = group[c_col].to_numpy()\n",
    "        row[out_col] = type2_regression_r2_pybroom(x, y)\n",
    "    results.append(row)\n",
    "\n",
    "# Convert to DataFrame\n",
    "r2_df = pd.DataFrame(results)\n",
    "r2_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a624c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_r2_heatmap(r2_df, time_thresh_hr=5, dist_thresh_km=10, r2_min=0.7, r2_max=0.99, r2_step=0.01):\n",
    "    \"\"\"\n",
    "    Plot a heatmap showing the number of unique CTD profiles that have R2 above given thresholds.\n",
    "    Each cell is annotated with the count.\n",
    "    \"\"\"\n",
    "    # Filter by time and distance thresholds\n",
    "    df = r2_df[(r2_df['time_diff_hr'] <= time_thresh_hr) & (r2_df['dist_km'] <= dist_thresh_km)]\n",
    "    \n",
    "    # Define specific R2 thresholds and variable names as requested\n",
    "    r2_thresholds = [0.99, 0.95, 0.9, 0.85, 0.8, 0.75, 0.7]\n",
    "    variables = ['r2_temp', 'r2_salinity', 'r2_chla', 'r2_bbp', 'r2_doxy']\n",
    "    var_labels = ['Temp', 'Salinity', 'Chla', 'BBP', 'Doxy']\n",
    "    \n",
    "    # Initialize heatmap matrix\n",
    "    heatmap = np.zeros((len(variables), len(r2_thresholds)), dtype=int)\n",
    "\n",
    "    # For each variable and threshold, count unique CTD profiles with R2 >= threshold\n",
    "    for i, var in enumerate(variables):\n",
    "        for j, thresh in enumerate(r2_thresholds):\n",
    "            mask = df[var] >= thresh\n",
    "            unique_ctd = df.loc[mask, 'ctd_profile_id'].nunique()\n",
    "            heatmap[i, j] = unique_ctd\n",
    "\n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    im = plt.imshow(heatmap, aspect='auto', cmap='PuBu', \n",
    "                    extent=[-0.5, len(r2_thresholds)-0.5, -0.5, len(variables)-0.5])\n",
    "    plt.colorbar(im, label='Number of Unique CTD Profiles')\n",
    "    \n",
    "    # Set axis labels and ticks\n",
    "    plt.yticks(range(len(variables)), var_labels)\n",
    "    plt.xticks(range(len(r2_thresholds)), [f'{t:.2f}' for t in r2_thresholds])\n",
    "    plt.xlabel('R² Threshold')\n",
    "    plt.ylabel('Variable')\n",
    "    plt.title(f'Unique CTD Profiles with R² ≥ Threshold\\n(Time ≤ {time_thresh_hr}hr, Distance ≤ {dist_thresh_km}km)')\n",
    "\n",
    "    # Annotate each cell with the exact count\n",
    "    for i in range(len(variables)):\n",
    "        for j in range(len(r2_thresholds)):\n",
    "            count = heatmap[i, j]\n",
    "            # Choose text color based on background intensity\n",
    "            text_color = 'white' if count > heatmap.max() / 2 else 'black'\n",
    "            plt.text(j, i, str(count), ha='center', va='center', \n",
    "                    color=text_color, fontsize=10, fontweight='bold')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab16354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the r2_df for each glider and run the heatmap function\n",
    "gliders = ['Nelson', 'Doombar', 'Churchill', 'Cabot']\n",
    "\n",
    "for glider in gliders:\n",
    "    # Filter the dataset for the current glider\n",
    "    filtered_r2_df = r2_df[r2_df['glider_profile_id'].str.contains(f\"_{glider}$\")]\n",
    "    \n",
    "    print(f\"\\n=== R² Heatmap for {glider} ===\")\n",
    "    plot_r2_heatmap(\n",
    "        filtered_r2_df,\n",
    "        time_thresh_hr=5,\n",
    "        dist_thresh_km=10\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccb4193",
   "metadata": {},
   "source": [
    "# Visualising the correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9ed5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_r2_df = r2_df[\n",
    "    (r2_df['r2_temp'] >= 0.95) |\n",
    "    (r2_df['r2_salinity'] >= 0.9) |\n",
    "    (r2_df['r2_chla'] >= 0.9) |\n",
    "    (r2_df['r2_bbp'] >= 0.9) |\n",
    "    (r2_df['r2_doxy'] >= 0.9)\n",
    "]\n",
    "\n",
    "print(f\"Filtered DataFrame contains {len(filtered_r2_df)} rows.\")\n",
    "filtered_r2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b7a205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a dictionary to store DataFrames for each variable\n",
    "variable_dfs = {}\n",
    "\n",
    "churchill_filtered = r2_df[r2_df['glider_profile_id'].str.contains(\"Churchill\")]\n",
    "# Iterate over each variable\n",
    "for var in ['r2_temp', 'r2_salinity', 'r2_chla', 'r2_bbp', 'r2_doxy']:\n",
    "    # Initialize an empty list to store the rows with the highest R² values for the current variable\n",
    "    selected_rows = []\n",
    "    \n",
    "    # Iterate over each unique CTD profile ID\n",
    "    for ctd_id in churchill_filtered['ctd_profile_id'].unique():\n",
    "        # Filter rows for the current CTD profile ID\n",
    "        ctd_rows = churchill_filtered[churchill_filtered['ctd_profile_id'] == ctd_id]\n",
    "        \n",
    "        # Select the row with the highest R² value for the current variable\n",
    "        max_row = ctd_rows.loc[ctd_rows[var].idxmax()]\n",
    "        selected_rows.append(max_row)\n",
    "    \n",
    "    # Create a DataFrame from the selected rows and store it in the dictionary\n",
    "    variable_dfs[var] = pd.DataFrame(selected_rows).drop_duplicates()\n",
    "\n",
    "# Access individual DataFrames using variable_dfs['r2_temp'], variable_dfs['r2_salinity'], etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5012a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_binned_data(variable_dfs, glider_binned, ctd_binned):\n",
    "    \"\"\"\n",
    "    Link variable_dfs with glider_binned and ctd_binned data to get full binned profile data.\n",
    "    \n",
    "    Parameters:\n",
    "    - variable_dfs: dict, DataFrames for each variable containing paired profiles.\n",
    "    - glider_binned: polars.DataFrame, binned data for glider profiles.\n",
    "    - ctd_binned: polars.DataFrame, binned data for CTD profiles.\n",
    "    \n",
    "    Returns:\n",
    "    - dict, updated variable_dfs with linked binned data.\n",
    "    \"\"\"\n",
    "    updated_dfs = {}\n",
    "    \n",
    "    for var, df in variable_dfs.items():\n",
    "        # Convert the current DataFrame to polars for efficient joining\n",
    "        df_pl = pl.from_pandas(df)\n",
    "        \n",
    "        # Join with glider_binned to get binned glider data\n",
    "        df_with_glider_bins = df_pl.join(\n",
    "            glider_binned,\n",
    "            left_on=\"glider_profile_id\",\n",
    "            right_on=\"profile_id\",\n",
    "            how=\"inner\"\n",
    "        )\n",
    "        \n",
    "        # Join with ctd_binned to get binned CTD data\n",
    "        df_with_ctd_bins = df_with_glider_bins.join(\n",
    "            ctd_binned,\n",
    "            left_on=[\"ctd_profile_id\", \"depth_bin\"],\n",
    "            right_on=[\"profile_idx\", \"depth_bin\"],\n",
    "            how=\"inner\"\n",
    "        )\n",
    "        \n",
    "        # Convert back to pandas for compatibility\n",
    "        updated_dfs[var] = df_with_ctd_bins.to_pandas()\n",
    "    \n",
    "    return updated_dfs\n",
    "\n",
    "# Example usage\n",
    "linked_variable_dfs = get_binned_data(variable_dfs, glider_binned, ctd_binned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fb65eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "#| fig-cap: \"Scaterplot of the CTD and glider values for multiple variables.\"\n",
    "from sklearn.linear_model import LinearRegression\n",
    "def plot_multi_panel_scatter(linked_variable_dfs, var_pairs):\n",
    "    \"\"\"\n",
    "    Create a multi-panel scatter plot comparing CTD and glider values for multiple variables.\n",
    "\n",
    "    Parameters:\n",
    "    - linked_variable_dfs: dict, DataFrames for each variable containing paired profiles.\n",
    "    - var_pairs: list of tuples, each containing (glider_column, ctd_column, variable_name).\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, len(var_pairs), figsize=(20, 6), sharex=False, sharey=False)\n",
    "    \n",
    "    for ax, (g_col, c_col, var) in zip(axes, var_pairs):\n",
    "        # Extract data for the current variable\n",
    "        df = linked_variable_dfs[var]\n",
    "        x = df[c_col].values\n",
    "        y = df[g_col].values\n",
    "        \n",
    "        # Perform linear regression\n",
    "        mask = np.isfinite(x) & np.isfinite(y)\n",
    "        x_clean = x[mask].reshape(-1, 1)\n",
    "        y_clean = y[mask]\n",
    "        if len(x_clean) > 0:\n",
    "            model = LinearRegression()\n",
    "            model.fit(x_clean, y_clean)\n",
    "            slope = model.coef_[0]\n",
    "            intercept = model.intercept_\n",
    "            equation = f\"y = {slope:.2f}x + {intercept:.2f}\"\n",
    "        else:\n",
    "            equation = \"No valid data\"\n",
    "\n",
    "        # Calculate mean distance in space and time\n",
    "        mean_dist_km = df['dist_km'].mean()\n",
    "        mean_time_diff_hr = df['time_diff_hr'].mean()\n",
    "\n",
    "        # Plot scatter\n",
    "        ax.scatter(x, y, alpha=0.7, edgecolor='k', label=f'{var}')\n",
    "        \n",
    "        # Add 1:1 regression line\n",
    "        min_val = min(x.min(), y.min())\n",
    "        max_val = max(x.max(), y.max())\n",
    "        ax.plot([min_val, max_val], [min_val, max_val], color='red', linestyle='--', label='1:1 Line')\n",
    "        \n",
    "        # Add regression line\n",
    "        if len(x_clean) > 0:\n",
    "            ax.plot(x_clean, model.predict(x_clean), color='blue', linestyle='-', label='Regression Line')\n",
    "        \n",
    "        # Set labels and title\n",
    "        ax.set_xlabel(f'CTD {var}')\n",
    "        ax.set_ylabel(f'Glider {var}')\n",
    "        ax.set_title(f'{var}: CTD vs Glider\\n{equation}\\nMean Dist: {mean_dist_km:.2f} km, Mean Time Diff: {mean_time_diff_hr:.2f} hr')\n",
    "        ax.grid(True)\n",
    "        ax.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "plot_multi_panel_scatter(linked_variable_dfs, var_pairs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "db_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
