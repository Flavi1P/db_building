{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gliders NPP time series analysis\n",
    "\n",
    "I will try here to make a timeseries analysis of NPP estimation from CbPM applied to gliders. I will grid and combined gliders together. Look at the mean and SD NPP transect. Resample over time to get one profile every hour. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from cmocean import cm as cmo\n",
    "import glidertools as gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doombar = xr.open_dataset('C:/Users/flapet/OneDrive - NOC/Documents/IDAPro/lib/db_building/data/glider/npp_ncdf/doombar_npp.nc')\n",
    "churchill = xr.open_dataset('C:/Users/flapet/OneDrive - NOC/Documents/IDAPro/lib/db_building/data/glider/npp_ncdf/churchill_npp.nc')\n",
    "nelson = xr.open_dataset('C:/Users/flapet/OneDrive - NOC/Documents/IDAPro/lib/db_building/data/glider/npp_ncdf/nelson_npp.nc')\n",
    "cabot = xr.open_dataset('C:/Users/flapet/OneDrive - NOC/Documents/IDAPro/lib/db_building/data/glider/npp_ncdf/cabot_npp.nc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gliders_npp_to_pl(glider_npp_xr, glider_name):\n",
    "\n",
    "    data = [\n",
    "        pl.Series(\"datetime\", glider_npp_xr['time'].data),\n",
    "        pl.Series(\"profile_index\", glider_npp_xr['profile_index'].data),\n",
    "        pl.Series(\"longitude\", glider_npp_xr['longitude'].data),\n",
    "        pl.Series(\"latitude\", glider_npp_xr['latitude'].data),\n",
    "        pl.Series(\"depth\", glider_npp_xr['depth_bin'].data),\n",
    "        pl.Series(\"temperature\", glider_npp_xr['temperature'].data),\n",
    "        pl.Series(\"salinity\", glider_npp_xr['salinity'].data), \n",
    "        pl.Series(\"fluo\", glider_npp_xr['fluo_corrected'].data),\n",
    "        pl.Series(\"bbp700\", glider_npp_xr['bbp700'].data),\n",
    "        pl.Series(\"par\", glider_npp_xr['PAR_matched'].data),\n",
    "        pl.Series(\"mu\", glider_npp_xr['mu'].data),\n",
    "        pl.Series(\"npp\", glider_npp_xr['pp'].data),\n",
    "        pl.Series(\"zeu\", glider_npp_xr['zeu'].data),\n",
    "        pl.Series(\"npp_vgpm\", glider_npp_xr['npp_vgpm'].data)]\n",
    "    \n",
    "    \n",
    "    if glider_name == \"churchill\" or glider_name == \"nelson\":\n",
    "        data.append(pl.Series(\"par_insitu\", glider_npp_xr['par_corr'].data))\n",
    "    elif glider_name == \"doombar\" or glider_name == \"cabot\":\n",
    "        data.append(pl.Series(\"par_insitu\", [None] * len(glider_npp_xr['time'].data)).cast(pl.Float64))\n",
    "    else:\n",
    "        print(\"Please enter a valid glider name\")\n",
    "\n",
    "    pl_df = pl.DataFrame(data)\n",
    "    pl_df = pl_df.with_columns(pl.lit(glider_name).alias('glider'))\n",
    "    return pl_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doombar_pl = gliders_npp_to_pl(doombar, \"doombar\")\n",
    "nelson_pl = gliders_npp_to_pl(nelson, \"nelson\")\n",
    "churchill_pl = gliders_npp_to_pl(churchill, \"churchill\")\n",
    "cabot_pl = gliders_npp_to_pl(cabot, \"cabot\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_round_hour(pl_df):\n",
    "\n",
    "    df = pl_df.with_columns(pl.col('datetime').cast(pl.Datetime))\n",
    "\n",
    "    # Identify the shallowest depth per profile (surface moment)\n",
    "    surface_moments = (\n",
    "        df.sort(['profile_index', 'depth'])\n",
    "        .group_by('profile_index')\n",
    "        .first()\n",
    "        .select(['profile_index', 'datetime'])\n",
    "    )\n",
    "\n",
    "    # Round the surface moment's datetime to the nearest hour\n",
    "    surface_moments = surface_moments.with_columns(\n",
    "        (pl.col('datetime').dt.truncate('1h') + \n",
    "        (pl.col('datetime').dt.minute().ge(30)).cast(pl.Int32) * pl.duration(hours=1)).alias('profile_hour')\n",
    "    )\n",
    "\n",
    "    # Ensure profile_hour is treated as a datetime (if needed)\n",
    "    surface_moments = surface_moments.with_columns(\n",
    "        pl.col('profile_hour').cast(pl.Datetime)\n",
    "    )\n",
    "\n",
    "    # Extract the hour as an integer and date as a date object\n",
    "    surface_moments = surface_moments.with_columns(\n",
    "        pl.col('profile_hour').dt.hour().alias('hour'),\n",
    "        pl.col('profile_hour').dt.date().cast(pl.Date).alias('date')\n",
    "    )\n",
    "\n",
    "    # Join the rounded hour and date back to the original DataFrame\n",
    "    df = df.join(surface_moments.select(['profile_index', 'hour', 'date']), on='profile_index')\n",
    "\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doombar_pl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gliders = pl.concat([doombar_pl, nelson_pl, churchill_pl, cabot_pl])\n",
    "gliders = add_round_hour(gliders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gliders = gliders.filter(pl.col(\"date\") < pl.date(2024, 10, 1))\n",
    "gliders.write_parquet('C:/Users/flapet/OneDrive - NOC/Documents/IDAPro/lib/db_building/data/glider/all_gliders_npp.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library & dataset\n",
    "import seaborn as sns\n",
    "\n",
    "sns.boxplot( x=gliders[\"hour\"], y=gliders[\"par\"] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "#plt.plot(bbp_raw, depths, label='Backscatter Raw', color='blue')\n",
    "plt.scatter(doombar_pl[\"bbp700\"], doombar_pl[\"npp\"], label='Par distribution')\n",
    "\n",
    "\n",
    "plt.ylabel(\"NPP (CbPM)\")\n",
    "plt.title(\"NPP as function of PAR data\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prof_per_day = (\n",
    "    gliders.filter(pl.col(\"depth\") == 1)\n",
    "    ).group_by([\"date\", \"hour\"]\n",
    "    ).agg(pl.col(\"depth\").mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "#plt.plot(bbp_raw, depths, label='Backscatter Raw', color='blue')\n",
    "plt.scatter(prof_per_day[\"date\"], prof_per_day[\"hour\"], label='N# of profile per day')\n",
    "\n",
    "plt.ylabel(\"Occurence\")\n",
    "plt.title(\"Date\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gliders_merged = (\n",
    "    gliders.group_by([\"date\", \"hour\", \"depth\"]\n",
    "    ).agg(pl.all().mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dates = pl.Series(\"date\", pd.date_range(gliders_merged[\"date\"].min(), gliders_merged[\"date\"].max()).strftime(\"%Y-%m-%d\").tolist()).cast(pl.Date)\n",
    "all_hours = pl.Series(\"hour\", list(range(0, 24))).cast(pl.Int8)\n",
    "all_depths = pl.Series(\"depth\", list(range(0, 201)))  # Depth from 0 to 200 meters\n",
    "\n",
    "# Create a complete grid of date-hour-depth combinations\n",
    "full_grid = (\n",
    "    all_dates.to_frame()\n",
    "    .join(all_hours.to_frame(), how=\"cross\")\n",
    "    .join(all_depths.to_frame(), how=\"cross\")\n",
    ")\n",
    "\n",
    "# Merge with original data to fill missing rows with NA\n",
    "full_df = full_grid.join(gliders_merged, on=[\"date\", \"hour\", \"depth\"], how=\"left\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a \"status\" column: \"data\" if an observation exists, otherwise \"missing\"\n",
    "full_df = full_df.with_columns(\n",
    "    pl.when(pl.col(\"profile_index\").is_null())\n",
    "    .then(pl.lit(\"missing\"))\n",
    "    .otherwise(pl.lit(\"Data\"))\n",
    "    .alias(\"status\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = full_df.filter(pl.col(\"depth\") == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.dpi\"] = 300\n",
    " \n",
    "# Use the 'hue' argument to provide a factor variable\n",
    "sns.scatterplot(\n",
    "   x=\"date\",\n",
    "   y=\"hour\",\n",
    "   data=plot_df,\n",
    "   hue='status',\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = [\"fluo\", \"bbp700\", \"par\", \"mu\", \"npp\"]\n",
    "full_df = full_df.with_columns(\n",
    "    (pl.col(\"date\").cast(pl.Utf8) + \" \" + pl.col(\"hour\").cast(pl.Utf8) + \":00\")\n",
    "    .str.to_datetime(\"%Y-%m-%d %H:%M\")\n",
    "    .alias(\"datetime\")\n",
    ")\n",
    "for col in numeric_cols:\n",
    "    full_df = full_df.sort([\"depth\", \"datetime\"]).with_columns(\n",
    "        full_df\n",
    "        .group_by(\"depth\")\n",
    "        .agg(\n",
    "            pl.col(\"datetime\"),\n",
    "            pl.col(col).interpolate().alias(col)  # Interpolate within each depth's timeseries\n",
    "        )\n",
    "        .explode([\"datetime\", col])  # Expand both datetime and interpolated column back into rows\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = full_df.filter(pl.col(\"status\") == \"data\")\n",
    "interpolated = full_df.filter(pl.col(\"status\") == \"missing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = full_df.filter(pl.col(\"npp\") < 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot( x=plot_df[\"fluo\"], y=plot_df[\"status\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.write_parquet('C:/Users/flapet/OneDrive - NOC/Documents/IDAPro/lib/db_building/data/glider/interpolated_npp.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.dpi\"] = 300\n",
    " \n",
    "# Use the 'hue' argument to provide a factor variable\n",
    "sns.scatterplot(\n",
    "   x=\"date\",\n",
    "   y=\"depth\",\n",
    "   data=full_df,\n",
    "   color='npp',\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "db_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
