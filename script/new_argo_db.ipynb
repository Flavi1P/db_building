{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import sys\n",
    "sys.path.append('C:/Users/flapet/OneDrive - NOC/Documents/utils_python')\n",
    "from functions.float_download import *\n",
    "import urllib3\n",
    "import shutil\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wmo_number = [6990636, 3901581, 1902695, 4903659, 7902223, 1902637, 3901586, 1902304, 4903532]\n",
    "wmo_number = [6904240, 7902223, 3901581, 6990636, 3902261, 3902258, 4903659, 3902260, 3901586, 1902304, 6901514, 6901515, 6904185, 4903365, 6901484]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 'C:/Users/flapet/OneDrive - NOC/Documents/IDAPro/lib/db_building'\n",
    "profile_dir = root + '/data/argo_nc/'\n",
    "natl_dir = profile_dir + 'North_Atlantic/'\n",
    "nitrate_floats = profile_dir + 'Nitrate_floats/'\n",
    "\n",
    "# Create GO-BGC folders if they do not exist yet\n",
    "if 'data' not in os.listdir(root):\n",
    "  os.mkdir(root + '/data')\n",
    "if 'argo_nc' not in os.listdir(root + '/data'):\n",
    "  os.mkdir(profile_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> File argo_synthetic-profile_index.txt already exists. Overwriting with new version.\n",
      ">>> Successfully downloaded argo_synthetic-profile_index.txt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users/flapet/OneDrive - NOC/Documents/utils_python\\functions\\float_download.py:107: FutureWarning: The argument 'date_parser' is deprecated and will be removed in a future version. Please use 'date_format' instead, or read your data in as 'object' dtype and then call 'to_datetime'.\n",
      "  gdac_index = pd.read_csv(save_to + index_filename,delimiter=',',header=8,parse_dates=['date','date_update'],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> File 1902304_Sprof.nc already exists. Overwriting with new version.\n",
      ">>> Successfully downloaded 1902304_Sprof.nc.\n",
      ">>> File 3902258_Sprof.nc already exists. Overwriting with new version.\n",
      ">>> Successfully downloaded 3902258_Sprof.nc.\n",
      ">>> File 3902260_Sprof.nc already exists. Overwriting with new version.\n",
      ">>> Successfully downloaded 3902260_Sprof.nc.\n",
      ">>> File 3902261_Sprof.nc already exists. Overwriting with new version.\n",
      ">>> Successfully downloaded 3902261_Sprof.nc.\n",
      ">>> File 4903365_Sprof.nc already exists. Overwriting with new version.\n",
      ">>> Successfully downloaded 4903365_Sprof.nc.\n",
      ">>> File 3901581_Sprof.nc already exists. Overwriting with new version.\n",
      ">>> Successfully downloaded 3901581_Sprof.nc.\n",
      ">>> File 3901586_Sprof.nc already exists. Overwriting with new version.\n",
      ">>> Successfully downloaded 3901586_Sprof.nc.\n",
      ">>> File 6904185_Sprof.nc already exists. Overwriting with new version.\n",
      ">>> Successfully downloaded 6904185_Sprof.nc.\n",
      ">>> File 4903659_Sprof.nc already exists. Overwriting with new version.\n",
      ">>> Successfully downloaded 4903659_Sprof.nc.\n",
      ">>> File 6901484_Sprof.nc already exists. Overwriting with new version.\n",
      ">>> Successfully downloaded 6901484_Sprof.nc.\n",
      ">>> File 6901514_Sprof.nc already exists. Overwriting with new version.\n",
      ">>> Successfully downloaded 6901514_Sprof.nc.\n",
      ">>> File 6901515_Sprof.nc already exists. Overwriting with new version.\n",
      ">>> Successfully downloaded 6901515_Sprof.nc.\n",
      ">>> File 6904240_Sprof.nc already exists. Overwriting with new version.\n",
      ">>> Successfully downloaded 6904240_Sprof.nc.\n",
      ">>> File 6990636_Sprof.nc already exists. Overwriting with new version.\n",
      ">>> Successfully downloaded 6990636_Sprof.nc.\n",
      ">>> File 7902223_Sprof.nc already exists. Overwriting with new version.\n",
      ">>> Successfully downloaded 7902223_Sprof.nc.\n"
     ]
    }
   ],
   "source": [
    "wmoids, gdac_index, downloaded_filenames \\\n",
    "                   = argo_gdac(floats=wmo_number, save_to=nitrate_floats, overwrite_index=True, overwrite_profiles=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flapet\\AppData\\Local\\Temp\\ipykernel_28324\\3396843694.py:17: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  ds[var] = (('N_PROF',), [np.nan] * ds.dims['N_PROF'])  # Create a variable with NaN values matching 'N_PROF'\n",
      "C:\\Users\\flapet\\AppData\\Local\\Temp\\ipykernel_28324\\3396843694.py:17: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  ds[var] = (('N_PROF',), [np.nan] * ds.dims['N_PROF'])  # Create a variable with NaN values matching 'N_PROF'\n",
      "C:\\Users\\flapet\\AppData\\Local\\Temp\\ipykernel_28324\\3396843694.py:17: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  ds[var] = (('N_PROF',), [np.nan] * ds.dims['N_PROF'])  # Create a variable with NaN values matching 'N_PROF'\n",
      "C:\\Users\\flapet\\AppData\\Local\\Temp\\ipykernel_28324\\3396843694.py:17: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  ds[var] = (('N_PROF',), [np.nan] * ds.dims['N_PROF'])  # Create a variable with NaN values matching 'N_PROF'\n",
      "C:\\Users\\flapet\\AppData\\Local\\Temp\\ipykernel_28324\\3396843694.py:17: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  ds[var] = (('N_PROF',), [np.nan] * ds.dims['N_PROF'])  # Create a variable with NaN values matching 'N_PROF'\n",
      "C:\\Users\\flapet\\AppData\\Local\\Temp\\ipykernel_28324\\3396843694.py:17: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  ds[var] = (('N_PROF',), [np.nan] * ds.dims['N_PROF'])  # Create a variable with NaN values matching 'N_PROF'\n",
      "C:\\Users\\flapet\\AppData\\Local\\Temp\\ipykernel_28324\\3396843694.py:17: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  ds[var] = (('N_PROF',), [np.nan] * ds.dims['N_PROF'])  # Create a variable with NaN values matching 'N_PROF'\n",
      "C:\\Users\\flapet\\AppData\\Local\\Temp\\ipykernel_28324\\3396843694.py:17: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  ds[var] = (('N_PROF',), [np.nan] * ds.dims['N_PROF'])  # Create a variable with NaN values matching 'N_PROF'\n",
      "C:\\Users\\flapet\\AppData\\Local\\Temp\\ipykernel_28324\\3396843694.py:17: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  ds[var] = (('N_PROF',), [np.nan] * ds.dims['N_PROF'])  # Create a variable with NaN values matching 'N_PROF'\n",
      "C:\\Users\\flapet\\AppData\\Local\\Temp\\ipykernel_28324\\3396843694.py:17: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  ds[var] = (('N_PROF',), [np.nan] * ds.dims['N_PROF'])  # Create a variable with NaN values matching 'N_PROF'\n",
      "C:\\Users\\flapet\\AppData\\Local\\Temp\\ipykernel_28324\\3396843694.py:17: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  ds[var] = (('N_PROF',), [np.nan] * ds.dims['N_PROF'])  # Create a variable with NaN values matching 'N_PROF'\n",
      "C:\\Users\\flapet\\AppData\\Local\\Temp\\ipykernel_28324\\3396843694.py:17: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  ds[var] = (('N_PROF',), [np.nan] * ds.dims['N_PROF'])  # Create a variable with NaN values matching 'N_PROF'\n",
      "C:\\Users\\flapet\\AppData\\Local\\Temp\\ipykernel_28324\\3396843694.py:17: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  ds[var] = (('N_PROF',), [np.nan] * ds.dims['N_PROF'])  # Create a variable with NaN values matching 'N_PROF'\n",
      "C:\\Users\\flapet\\AppData\\Local\\Temp\\ipykernel_28324\\3396843694.py:17: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  ds[var] = (('N_PROF',), [np.nan] * ds.dims['N_PROF'])  # Create a variable with NaN values matching 'N_PROF'\n",
      "C:\\Users\\flapet\\AppData\\Local\\Temp\\ipykernel_28324\\3396843694.py:17: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  ds[var] = (('N_PROF',), [np.nan] * ds.dims['N_PROF'])  # Create a variable with NaN values matching 'N_PROF'\n"
     ]
    }
   ],
   "source": [
    "variables = ['PLATFORM_NUMBER', 'N_PROF', 'JULD', 'LONGITUDE', 'LATITUDE', 'PRES', 'TEMP', 'PSAL', 'CHLA_ADJUSTED', 'CHLA_ADJUSTED_QC', 'BBP700_ADJUSTED', 'BBP700_ADJUSTED_QC', 'DOWNWELLING_PAR', 'DOWN_IRRADIANCE490', 'NITRATE_ADJUSTED', 'NITRATE_ADJUSTED_QC', 'DOXY_ADJUSTED']\n",
    "\n",
    "df_list = []\n",
    "\n",
    "\n",
    "for filename in [f for f in os.listdir(nitrate_floats) if os.path.isfile(os.path.join(nitrate_floats, f)) and f.endswith('.nc')]:\n",
    "    filepath = os.path.join(nitrate_floats, filename)\n",
    "    ds = xr.open_dataset(filepath)\n",
    "    \n",
    "    # Check for missing variables\n",
    "    available_vars = set(ds.data_vars.keys())  # All variables in the current dataset\n",
    "    missing_vars = [var for var in variables if var not in available_vars]\n",
    "    \n",
    "    # Add missing variables to the dataset with NaN values, matching the dimensions\n",
    "    for var in missing_vars:\n",
    "        if 'N_PROF' in ds.dims:  # If the dataset has the 'N_PROF' dimension\n",
    "            ds[var] = (('N_PROF',), [np.nan] * ds.dims['N_PROF'])  # Create a variable with NaN values matching 'N_PROF'\n",
    "        else:\n",
    "            ds[var] = np.nan  # If no dimensions, add as a scalar (unlikely for most BGC-Argo data)\n",
    "\n",
    "    # Convert xarray Dataset to Polars DataFrame\n",
    "    df = pl.DataFrame(ds[variables].to_dataframe())  # Convert selected variables to a DataFrame\n",
    "    \n",
    "    # Cast float columns to Float64 for consistency\n",
    "    float_cols = [col for col in df.columns if df[col].dtype in [pl.Float32, pl.Float64]]\n",
    "    df = df.with_columns([pl.col(col).cast(pl.Float64) for col in float_cols])  # Ensure all floats are Float64\n",
    "    \n",
    "    # Convert PLATFORM_NUMBER to a string\n",
    "    df = df.with_columns(pl.col(\"PLATFORM_NUMBER\").cast(pl.Utf8))\n",
    "    \n",
    "    df_list.append(df)\n",
    "    \n",
    "# Concatenate all DataFrames into one\n",
    "argo_table = pl.concat(df_list)\n",
    "\n",
    "argo_table.write_parquet(root + '/data/argo_pq/biocarbon_nitrate_floats_table.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (15, 2)\n",
      "┌─────────────────┬────────┐\n",
      "│ PLATFORM_NUMBER ┆ len    │\n",
      "│ ---             ┆ ---    │\n",
      "│ str             ┆ u32    │\n",
      "╞═════════════════╪════════╡\n",
      "│ 4903659         ┆ 101048 │\n",
      "│ 6901514         ┆ 52611  │\n",
      "│ 6901515         ┆ 108186 │\n",
      "│ 6904185         ┆ 226270 │\n",
      "│ 3902260         ┆ 19456  │\n",
      "│ …               ┆ …      │\n",
      "│ 6904240         ┆ 154088 │\n",
      "│ 7902223         ┆ 28728  │\n",
      "│ 4903365         ┆ 68370  │\n",
      "│ 6901484         ┆ 87490  │\n",
      "│ 1902304         ┆ 98512  │\n",
      "└─────────────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "res = argo_table.group_by(['PLATFORM_NUMBER']).len()\n",
    "print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "db_env (3.10.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
